# Leader-Follower (LeFo): Signal Prediction for Loss Mitigation in Tactile Internet

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![IEEE MLSP 2025](https://img.shields.io/badge/IEEE-MLSP%202025-green.svg)](https://2025.ieeemlsp.org/)

Official implementation of the paper **"Signal Prediction for Loss Mitigation in Tactile Internet: A Leader-Follower Game-Theoretic Approach"** accepted at **IEEE International Workshop on Machine Learning for Signal Processing (MLSP) 2025**, Istanbul, Turkey.

## ğŸ“– Abstract

Tactile Internet (TI) requires achieving ultra-low latency and highly reliable packet delivery for haptic signals. In the presence of packet loss and delay, the signal prediction method provides a viable solution for recovering the missing signals. We introduce the **Leader-Follower (LeFo)** approach based on a cooperative Stackelberg game, which enables both users and robots to learn and predict actions. Our method achieves high prediction accuracy, ranging from **80.62% to 95.03%** for remote robot signals at the Human side and from **70.44% to 89.77%** for human operation signals at the remote Robot side.

## ğŸ¯ Key Features

- **Game-Theoretic Framework**: Novel Stackelberg game formulation for human-robot interaction
- **MiniMax Optimization**: Bidirectional predictive modeling with KL divergence and Mutual Information
- **KNN-based MI Estimation**: Non-parametric mutual information estimation using K-Nearest Neighbors
- **Taylor Expansion Upper Bound**: Theoretical guarantee for model robustness against signal loss
- **Multi-Feature Prediction**: Supports position, velocity, and force prediction in 3D space

## ğŸ—ï¸ Architecture

<img width="1273" height="479" alt="Screenshot 2025-12-29 at 16 31 17" src="https://github.com/user-attachments/assets/b7042900-3dfc-46f4-91ac-6bc6c1585cc2" />




## ğŸ“ Project Structure

```
lefo-tactile-internet/
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ LICENSE                     # MIT License
â”œâ”€â”€ setup.py                    # Package installation
â”œâ”€â”€ pyproject.toml             # Modern Python packaging
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ .gitignore                 # Git ignore patterns
â”‚
â”œâ”€â”€ configs/                   # Configuration files
â”‚   â”œâ”€â”€ default.yaml          # Default hyperparameters
â”‚   â””â”€â”€ experiment_configs/   # Experiment-specific configs
â”‚
â”œâ”€â”€ src/lefo/                  # Main source code
â”‚   â”œâ”€â”€ __init__.py           # Package initialization
â”‚   â”œâ”€â”€ models.py             # Neural network architectures
â”‚   â”œâ”€â”€ data.py               # Data loading and preprocessing
â”‚   â”œâ”€â”€ game.py               # Game theory components
â”‚   â”œâ”€â”€ train.py              # Training logic
â”‚   â”œâ”€â”€ evaluate.py           # Evaluation metrics
â”‚   â”œâ”€â”€ utils.py              # Utility functions
â”‚   â”œâ”€â”€ config.py             # Configuration management
â”‚   â””â”€â”€ visualization.py      # Plotting and visualization
â”‚
â”œâ”€â”€ scripts/                   # Executable scripts
â”‚   â”œâ”€â”€ train.py              # Training script
â”‚   â”œâ”€â”€ evaluate.py           # Evaluation script
â”‚   â”œâ”€â”€ inference.py          # Real-time inference
â”‚   â””â”€â”€ visualize_results.py  # Generate figures
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_training.ipynb
â”‚   â”œâ”€â”€ 03_results_analysis.ipynb
â”‚   â””â”€â”€ 04_upper_bound_verification.ipynb
â”‚
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_game.py
â”‚   â”œâ”€â”€ test_data.py
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ figures/                   # Generated figures
â”‚   â””â”€â”€ generate_paper_figures.py
â”‚
â”œâ”€â”€ data/                      # Dataset directory
â”‚   â””â”€â”€ README.md             # Dataset download instructions
â”‚
â””â”€â”€ docs/                      # Documentation
    â”œâ”€â”€ installation.md
    â”œâ”€â”€ usage.md
    â””â”€â”€ api_reference.md
```

## ğŸš€ Installation

### Prerequisites

- Python 3.8+
- CUDA 11.0+ (for GPU support)
- pip or conda

### Install from source

```bash
# Clone the repository
git clone https://github.com/Ali-Vahedifar/Leader-Follower-LeFo.git
cd Leader-Follower-LeFo

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install package in development mode
pip install -e .
```

### Install with pip

```bash
pip install lefo-tactile
```

## ğŸ“Š Dataset

We use real-world haptic data traces from kinaesthetic interactions recorded using a **Novint Falcon haptic device** within a **Chai3D virtual environment**.

### Dataset Types

| Dataset | Description | Samples |
|---------|-------------|---------|
| Drag Max Stiffness Y | Dragging motion with maximum stiffness | ~10,000 |
| Horizontal Movement Fast | Fast horizontal free-air movement | ~8,000 |
| Horizontal Movement Slow | Slow horizontal free-air movement | ~12,000 |
| Tap and Hold Max Stiffness Z-Fast | Fast tapping and holding | ~9,000 |
| Tap and Hold Max Stiffness Z-Slow | Slow tapping and holding | ~11,000 |
| Tapping Max Stiffness Y-Z | Tapping with dual-axis stiffness | ~10,000 |
| Tapping Max Stiffness Z | Tapping with Z-axis stiffness | ~10,000 |

### Download Dataset

```bash
# Download from Zenodo
python scripts/download_data.py --output data/

# Or manually download from:
# https://zenodo.org/record/14924062
```

## ğŸ® Usage

### Quick Start

```python
from lefo import LeaderFollowerModel, HapticDataset, Trainer
from lefo.config import Config

# Load configuration
config = Config.from_yaml('configs/default.yaml')

# Load dataset
dataset = HapticDataset(
    data_path='data/drag_max_stiffness_y.csv',
    deadband_threshold=0.1
)

# Initialize model
model = LeaderFollowerModel(
    human_layers=12,
    robot_layers=8,
    hidden_units=100,
    dropout=0.5
)

# Train
trainer = Trainer(model, config)
trainer.fit(dataset)

# Predict
predictions = model.predict(test_data)
```

### Training

```bash
# Train with default configuration
python scripts/train.py --config configs/default.yaml

# Train specific dataset
python scripts/train.py \
    --dataset drag_max_stiffness_y \
    --epochs 100 \
    --batch_size 32 \
    --lr 0.01

# Multi-GPU training
python scripts/train.py --config configs/default.yaml --gpus 0,1,2,3
```

### Evaluation

```bash
# Evaluate trained model
python scripts/evaluate.py \
    --checkpoint checkpoints/best_model.pt \
    --dataset data/test_data.csv

# Generate inference time benchmark
python scripts/evaluate.py --benchmark --iterations 1000
```

### Visualization

```bash
# Generate all paper figures
python figures/generate_paper_figures.py --output figures/

# Interactive visualization
python scripts/visualize_results.py --interactive
```

## ğŸ“ˆ Results

### Prediction Accuracy

| Dataset | Human Side (%) | Robot Side (%) |
|---------|---------------|----------------|
| Drag Max Stiffness Y | 95.03 Â± 0.8 | 89.77 Â± 1.2 |
| Horizontal Movement Fast | 92.45 Â± 0.6 | 85.32 Â± 0.9 |
| Horizontal Movement Slow | 93.78 Â± 0.7 | 87.44 Â± 1.0 |
| Tap and Hold Z-Fast | 88.21 Â± 1.1 | 78.56 Â± 1.5 |
| Tap and Hold Z-Slow | 90.67 Â± 0.9 | 82.11 Â± 1.3 |
| Tapping Max Y-Z | 82.34 Â± 1.4 | 72.89 Â± 1.8 |
| Tapping Max Z | 80.62 Â± 1.5 | 70.44 Â± 1.9 |

### Inference Time

| Dataset | Position (ms) | Velocity (ms) | Force (ms) |
|---------|--------------|---------------|------------|
| Drag Max Stiffness Y | 7.5-9.1 | 6.8-8.5 | 10.9-12.3 |
| Horizontal Movement Fast | 6.5-7.1 | 6.2-7.8 | 8.7-10.2 |
| Horizontal Movement Slow | 9.8-11.2 | 8.9-10.1 | 13.8-15.2 |

## ğŸ”¬ Theoretical Analysis

### Upper Bound for Loss Function

We establish an upper bound using Taylor expansion:

```
L_{n-1}(Î¸_n) - L_{n-1}(Î¸_{n-1}) â‰¤ (1/2) Î»_max^{n-1} ||Î”Î¸||Â²
```

where `Î»_max^{n-1}` is the largest eigenvalue of the Hessian matrix.

### Verify Upper Bound

```python
from lefo.analysis import verify_upper_bound

# Verify theoretical bounds
results = verify_upper_bound(
    model=trained_model,
    dataset=test_dataset,
    compute_hessian=True
)
print(f"Loss: {results['loss']:.4f}")
print(f"Upper Bound: {results['upper_bound']:.4f}")
print(f"Bound Satisfied: {results['satisfied']}")
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test module
pytest tests/test_models.py -v

# Run with coverage
pytest tests/ --cov=lefo --cov-report=html
```

## ğŸ“š Citation

If you use this code in your research, please cite our paper:

```bibtex
@INPROCEEDINGS{11204284,
  author={Ali Vahedifar, Mohammad and Zhang, Qi},
  booktitle={2025 IEEE 35th International Workshop on Machine Learning for Signal Processing (MLSP)}, 
  title={Signal Prediction for Loss Mitigation in Tactile Internet: a Leader-Follower Game-Theoretic Approach}, 
  year={2025},
  volume={},
  number={},
  pages={01-06},
  keywords={Tactile Internet;Accuracy;Upper bound;Packet loss;Signal processing algorithms;Games;Taylor series;Robustness;Delays;Robots;Tactile Internet;Signal Prediction;Stackelberg Game;Neural Network;Game Theory},
  doi={10.1109/MLSP62443.2025.11204284}}

```

## ğŸ¤ Contributing

Contributions are welcome! Please read our [Contributing Guidelines](CONTRIBUTING.md) before submitting a pull request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

This research was supported by:
- **TOAST Project**: European Union's Horizon Europe research and innovation program under Marie SkÅ‚odowska-Curie Actions Doctoral Network (Grant Agreement No. 101073465)
- **NordForsk**: Nordic University Cooperation on Edge Intelligence (Grant No. 168043)

## ğŸ“§ Contact

- **Mohammad Ali Vahedifar** - av@ece.au.dk
  

DIGIT and Department of Electrical and Computer Engineering, Aarhus University, Denmark

---

<p align="center">
  <b>â­ Star this repository if you find it useful! â­</b>
</p>
